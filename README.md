# ðŸŽ¶ Improvise a Jazz Solo with an LSTM Network ðŸŽ¶

Welcome to the **Improvise a Jazz Solo with an LSTM Network** project! This repository demonstrates the use of a Long Short-Term Memory **(LSTM)** network to generate jazz music solos. This project builds upon existing work.

![Deep Learning](https://img.shields.io/badge/Skill-Deep%20Learning-yellow)
![Sequence Modeling](https://img.shields.io/badge/Skill-Sequence%20Modeling-blueviolet)
![Generative Models](https://img.shields.io/badge/Skill-Generative%20Models-green)
![Model Training and Evaluation](https://img.shields.io/badge/Skill-Model%20Training%20and%20Evaluation-orange)
![Python Programming](https://img.shields.io/badge/Skill-Python%20Programming-brightgreen)

## Key Features
- **Deep Learning**: Utilise an LSTM network for music generation.
- **Sequence Modeling**: Handle time series data and sequences effectively.
- **Generative Models**: Create new jazz solos based on learned patterns.
- **Music Processing**: Use the Music21 library for musical data manipulation.
## Usage
**Clone the Repository:**
```bash
jupyter notebook Improvise_a_Jazz_Solo_with_an_LSTM_Network_v4.ipynb
```
**Install Dependencies:**
```bash
pip install -r requirements.txt
```
**Run the Jupyter Notebook:**
```bash
git clone https://github.com/yourusername/jazz-solo-lstm.git
```
## Implementation
The project involves the following steps:

- **Data Preparation:** Preparing musical data for training using existing utilities.
- **Model Training:** Building and training the LSTM network with my modifications.
- **Music Generation:** Generating new jazz solos using the trained model.

**Training Loss**
Below is the plot of the training loss, showing how the model improved over time:

<img src="images\image.png" style="width:400px;">

## Results
**Audio Samples**
Scan the QR Code and listen to the generated jazz solo:

<img src="output\frame.png" style="width:200px;">
